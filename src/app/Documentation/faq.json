[
  {
    "id": "1",
    "question": "What are the supported SLO classes?",
    "answer": "Right now supported classes are Response time, throughput & resource usage. We arrived manually in these classes. We may add more such classes in the future. At a time the objective function caters to only one particular slo class."
  },
  {
    "id": "2",
    "question": "How are the tunables specified?",
    "answer": " Under autotune/ manifest/ autotune-configs - there are different YAML files in which several layers are defined for eg. hotspot, quarkus. These YAML files contain tunables with their value type and range."
  },
  {
    "id": "3",
    "question": "While running the experiment, does autotune has several pods receiving multiple requests or is it just single pod since it is cost incurring",
    "answer": " Yes, right now we are limited to only one single pod to tune a particular microservice for the mvp (minimum viable product) but we plan to extend it for other microservices/ multiple pods"
  },
  {
    "id": "4",
    "question": "Do you have any plans to have companies develop their own forks based on autotune as open source?",
    "answer": "A. Really welcome contributions from other contributors and would preferably want them to jointly look at common/current issues in autotune before they start working with their own forks as autotune is in its initial stages thus needs some time before it can be developed specifically by other companies"
  },
  {
    "id": "5",
    "question": "In addition to goals and progress , we see that debug loops and troubleshooting are important parts of the SRE work load. Does autotune look into diagnosing and debugging paths for the SRE?Can it find the degraded service and the reason behind degradation? Basically if autotune can work beyond performance tuning and optimization",
    "answer": "A. We haven't yet looked into autotune specifically from a debugging perspective. In the hands of runtime developers they can pick and choose a tunable and see only the effects of one tunable on overall performance and if that leads into an error autotune can be of use. But debugging in a live environment is not a scenario that we currently have in mind. But Autotune helps runtime developers analyze large search space (30-50 tunables) when they are not aware how each tunable will perform over time."
  },
  {
    "id": "6",
    "question": "Can Autotune give information about the cost of a cluster w.r.t money and resources for a customer",
    "answer": "We are working on the analyser recommendation manager to get complete workflow working. The current mvp focus is to optimize stack to get best performance at individual pod level. We plan to Horizontally scale in the future."
  }
]
